{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from plotly import offline as plotly\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "plotly.init_notebook_mode(True)\n",
    "np = pd.np\n",
    "\n",
    "### Hyper Parameters\n",
    "LEARNING_RATE = 0.00001 # 0.01 and 0.005 worked eventually\n",
    "BATCH_SIZE = 25000\n",
    "NUM_EPOCHS = 1\n",
    "INPUT_SIZE = NUM_FEATURES = 1\n",
    "HIDDEN_SIZE = 200\n",
    "NUM_CLASSES = 2\n",
    "SEQ_LENGTH = 10\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 36/87 [00:49<01:10,  1.37s/it]"
     ]
    }
   ],
   "source": [
    "def read_returns(pair):\n",
    "    path = f's3://mikeokslonger-ticks/returns.parquet/pair={pair}/part.0.parquet'\n",
    "    df = pd.read_parquet(path, columns=['time', 'relative_returns', 'buy', 'quantity', 'price'])\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    one_hot = np.array([[1, 0],\n",
    "                       [0, 1]], dtype='float32')\n",
    "    df['buy'] = df['buy'].astype(float)\n",
    "    df['label'] = (df.shift(-1)['relative_returns'] > 0.).astype(int)\n",
    "    df['label_onehot'] = df['label'].apply(lambda i: one_hot[i])\n",
    "    df['time'] = (df['time'] - 20180101000000).astype(float)\n",
    "    return df[1:]\n",
    "\n",
    "pairs = ['ADX-USD', 'AIR-USD', 'AMM-USD', 'ATB-USD', 'ATM-USD', 'B2X-USD', 'BCC-USD', 'BCH-USD', 'BCN-USD', 'BMC-USD', 'BNT-USD', 'BQX-USD', 'BTCA-USD', 'BTC-USD', 'BTG-USD', 'BTM-USD', 'BTX-USD', 'CAT-USD', 'CDT-USD', 'CLD-USD', 'CL-USD', 'CND-USD', 'CTR-USD', 'CVC-USD', 'DASH-USD', 'DATA-USD', 'DCN-USD', 'DGB-USD', 'DIM-USD', 'DOGE-USD', 'EBTCOLD-USD', 'EDO-USD', 'EMGO-USD', 'ENJ-USD', 'EOS-USD', 'ETC-USD', 'ETH-USD', 'ETP-USD', 'EVX-USD', 'FUEL-USD', 'FUN-USD', 'ICOS-USD', 'ICX-USD', 'KMD-USD', 'LOC-USD', 'LSK-USD', 'LTC-USD', 'MAID-USD', 'MANA-USD', 'MCO-USD', 'NEO-USD', 'NGC-USD', 'NXT-USD', 'OAX-USD', 'OMG-USD', 'PLR-USD', 'PPC-USD', 'PRG-USD', 'QTUM-USD', 'SMART-USD', 'SMS-USD', 'SNC-USD', 'SNT-USD', 'STRAT-USD', 'STU-USD', 'STX-USD', 'SUB-USD', 'SUR-USD', 'SWFTC-USD', 'TNT-USD', 'TRX-USD', 'UGT-USD', 'UTT-USD', 'VEN-USD', 'VERI-USD', 'VIB-USD', 'WMGO-USD', 'WRC-USD', 'XDN-USD', 'XEM-USD', 'XMR-USD', 'XTZ-USD', 'XUC-USD', 'XVG-USD', 'ZEC-USD', 'ZRX-USD', 'ZSC-USD']\n",
    "pairs = pairs\n",
    "df = pd.concat([create_features(read_returns(pair)) for pair in tqdm.tqdm(pairs)]) # Full dataset\n",
    "df = df[df.relative_returns.abs() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38337223"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticks(Dataset):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.x_data = data[:, 1:2].copy().astype('float32')\n",
    "        self.y_data = data[:, -1].copy()#.astype('int')\n",
    "        \n",
    "        indices = pd.DataFrame(data[:, -2] == 0,columns=['isnegative']).reset_index()\n",
    "        positive_indices = indices[~indices.isnegative]['index']\n",
    "        negative_indices = indices[indices.isnegative]['index']\n",
    "        negative_indices_resampled = negative_indices.sample(frac=len(positive_indices)/len(negative_indices))\n",
    "        self.new_indices = pd.np.concatenate([positive_indices, negative_indices_resampled])\n",
    "        self.new_indices.sort()\n",
    "        \n",
    "        self.len = len(self.new_indices) - SEQ_LENGTH - ((len(self.new_indices) - SEQ_LENGTH) % batch_size)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        new_index = self.new_indices[index]\n",
    "        x = self.x_data[new_index: new_index + SEQ_LENGTH]\n",
    "        return x, self.y_data[new_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "#        return 1000000\n",
    "        return self.len\n",
    "\n",
    "\n",
    "test_validation_split = int(len(df) * 0.8)\n",
    "dataset_train = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[:test_validation_split], BATCH_SIZE)\n",
    "dataset_test = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[test_validation_split:], BATCH_SIZE)\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Model\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### (LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda() # Hidden\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda() # Cell state\n",
    "        _, (h_out, _) = self.lstm(x, (h0, c0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        activated = self.sig(out)\n",
    "        return activated\n",
    "\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "test_predicted_positives = []\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "lstm = LSTM(NUM_CLASSES, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS).cuda()\n",
    "lstm.load_state_dict(torch.load('models/180.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 218/1\n",
      "actual positive returns 2511737.0/5025000: 4.7842609523809525\n",
      "predicted positive_returns 3642226/5025000: 0.7248210945273632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:04<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4986577033996582, accuracy: 0.7441638095238096\n",
      "actual positive returns 261045.0/525000: 0.4972285714285714\n",
      "predicted positive_returns 378141/525000: 0.7202685714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "loss",
         "type": "scatter",
         "uid": "9b8db4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          0.46162885427474976,
          0.4669307768344879,
          0.46500164270401,
          0.45684102177619934,
          0.4628540277481079,
          0.4609185457229614,
          0.45344704389572144,
          0.4559299349784851,
          0.4586683511734009,
          0.44989514350891113,
          0.44784191250801086,
          0.4523352086544037,
          0.44803914427757263,
          0.4434927999973297,
          0.45364031195640564,
          0.4452703893184662,
          0.4465751051902771,
          0.4472513794898987
         ]
        },
        {
         "name": "train_accuracy",
         "type": "scatter",
         "uid": "fb0383",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          0.7467217910447761,
          0.7481090547263681,
          0.749089552238806,
          0.7499251741293532,
          0.7506169154228856,
          0.7511725373134328,
          0.7517416915422885,
          0.7522887562189055,
          0.7527319402985074,
          0.7531490547263682,
          0.7534189054726368,
          0.7535472636815921,
          0.7537150248756219,
          0.7538441791044777,
          0.7539617910447761,
          0.7540585074626865,
          0.7541393034825871,
          0.7542087562189055
         ],
         "yaxis": "y2"
        },
        {
         "name": "test_accuracy",
         "type": "scatter",
         "uid": "0d6058",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          0.7353390476190477,
          0.7364857142857143,
          0.7380895238095239,
          0.7397580952380952,
          0.739792380952381,
          0.7408647619047619,
          0.7417219047619048,
          0.7420133333333333,
          0.7430609523809524,
          0.7435219047619047,
          0.7434038095238096,
          0.7439180952380953,
          0.7438342857142857,
          0.7439733333333334,
          0.7441733333333334,
          0.7438895238095238,
          0.74432,
          0.7441638095238096
         ],
         "yaxis": "y2"
        },
        {
         "name": "test_predicted_positives",
         "type": "scatter",
         "uid": "692fff",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          0.7042095238095238,
          0.7061828571428571,
          0.7095619047619047,
          0.7134019047619048,
          0.7133714285714285,
          0.7153733333333333,
          0.7165580952380952,
          0.7163390476190477,
          0.7189523809523809,
          0.7196304761904762,
          0.7187504761904762,
          0.7202742857142858,
          0.7205638095238095,
          0.7203219047619047,
          0.7210514285714286,
          0.7196971428571428,
          0.7207790476190477,
          0.7202685714285715
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "autosize": true,
        "xaxis": {
         "autorange": true,
         "range": [
          -1.0182984047544574,
          18.018298404754457
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.4415585980253312,
          0.4688649788064864
         ],
         "title": "loss",
         "type": "linear"
        },
        "yaxis2": {
         "autorange": true,
         "overlaying": "y",
         "range": [
          0.7000833735621477,
          0.7583349064662817
         ],
         "side": "right",
         "title": "accuracy",
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"b2039c86-4dfb-4bd5-a243-0417e67c7017\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b2039c86-4dfb-4bd5-a243-0417e67c7017\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.46162885427474976, 0.4669307768344879, 0.46500164270401, 0.45684102177619934, 0.4628540277481079, 0.4609185457229614, 0.45344704389572144, 0.4559299349784851, 0.4586683511734009, 0.44989514350891113, 0.44784191250801086, 0.4523352086544037, 0.44803914427757263, 0.4434927999973297, 0.45364031195640564, 0.4452703893184662, 0.4465751051902771, 0.4472513794898987], \"name\": \"loss\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7467217910447761, 0.7481090547263681, 0.749089552238806, 0.7499251741293532, 0.7506169154228856, 0.7511725373134328, 0.7517416915422885, 0.7522887562189055, 0.7527319402985074, 0.7531490547263682, 0.7534189054726368, 0.7535472636815921, 0.7537150248756219, 0.7538441791044777, 0.7539617910447761, 0.7540585074626865, 0.7541393034825871, 0.7542087562189055], \"name\": \"train_accuracy\", \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7353390476190477, 0.7364857142857143, 0.7380895238095239, 0.7397580952380952, 0.739792380952381, 0.7408647619047619, 0.7417219047619048, 0.7420133333333333, 0.7430609523809524, 0.7435219047619047, 0.7434038095238096, 0.7439180952380953, 0.7438342857142857, 0.7439733333333334, 0.7441733333333334, 0.7438895238095238, 0.74432, 0.7441638095238096], \"name\": \"test_accuracy\", \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7042095238095238, 0.7061828571428571, 0.7095619047619047, 0.7134019047619048, 0.7133714285714285, 0.7153733333333333, 0.7165580952380952, 0.7163390476190477, 0.7189523809523809, 0.7196304761904762, 0.7187504761904762, 0.7202742857142858, 0.7205638095238095, 0.7203219047619047, 0.7210514285714286, 0.7196971428571428, 0.7207790476190477, 0.7202685714285715], \"name\": \"test_predicted_positives\", \"yaxis\": \"y2\"}], {\"yaxis\": {\"title\": \"loss\"}, \"yaxis2\": {\"title\": \"accuracy\", \"overlaying\": \"y\", \"side\": \"right\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"b2039c86-4dfb-4bd5-a243-0417e67c7017\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b2039c86-4dfb-4bd5-a243-0417e67c7017\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.46162885427474976, 0.4669307768344879, 0.46500164270401, 0.45684102177619934, 0.4628540277481079, 0.4609185457229614, 0.45344704389572144, 0.4559299349784851, 0.4586683511734009, 0.44989514350891113, 0.44784191250801086, 0.4523352086544037, 0.44803914427757263, 0.4434927999973297, 0.45364031195640564, 0.4452703893184662, 0.4465751051902771, 0.4472513794898987], \"name\": \"loss\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7467217910447761, 0.7481090547263681, 0.749089552238806, 0.7499251741293532, 0.7506169154228856, 0.7511725373134328, 0.7517416915422885, 0.7522887562189055, 0.7527319402985074, 0.7531490547263682, 0.7534189054726368, 0.7535472636815921, 0.7537150248756219, 0.7538441791044777, 0.7539617910447761, 0.7540585074626865, 0.7541393034825871, 0.7542087562189055], \"name\": \"train_accuracy\", \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7353390476190477, 0.7364857142857143, 0.7380895238095239, 0.7397580952380952, 0.739792380952381, 0.7408647619047619, 0.7417219047619048, 0.7420133333333333, 0.7430609523809524, 0.7435219047619047, 0.7434038095238096, 0.7439180952380953, 0.7438342857142857, 0.7439733333333334, 0.7441733333333334, 0.7438895238095238, 0.74432, 0.7441638095238096], \"name\": \"test_accuracy\", \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"y\": [0.7042095238095238, 0.7061828571428571, 0.7095619047619047, 0.7134019047619048, 0.7133714285714285, 0.7153733333333333, 0.7165580952380952, 0.7163390476190477, 0.7189523809523809, 0.7196304761904762, 0.7187504761904762, 0.7202742857142858, 0.7205638095238095, 0.7203219047619047, 0.7210514285714286, 0.7196971428571428, 0.7207790476190477, 0.7202685714285715], \"name\": \"test_predicted_positives\", \"yaxis\": \"y2\"}], {\"yaxis\": {\"title\": \"loss\"}, \"yaxis2\": {\"title\": \"accuracy\", \"overlaying\": \"y\", \"side\": \"right\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 9.8710e-01  1.3803e-02\n",
      " 1.3796e-01  8.5563e-01\n",
      " 3.8216e-01  6.2838e-01\n",
      "           ⋮            \n",
      " 2.9930e-01  6.9254e-01\n",
      " 2.5692e-01  7.6269e-01\n",
      " 3.3767e-01  6.7067e-01\n",
      "[torch.cuda.FloatTensor of size 25000x2 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 40/201 [00:10<00:41,  3.89it/s]Process Process-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-74:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 121, in default_collate\n",
      "    return torch.stack([torch.from_numpy(b) for b in batch], 0)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 121, in <listcomp>\n",
      "    return torch.stack([torch.from_numpy(b) for b in batch], 0)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 134, in default_collate\n",
      "    transposed = zip(*batch)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-59e6e9cbae72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpredicted_positive_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_put_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"buffer length < offset + size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# and we'd better avoid the cost of concatenation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# Issue #20540: concatenate before sending, to avoid delays due\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in list(range(300, 400)):\n",
    "    correct = 0\n",
    "    num_positive_returns = 0\n",
    "    predicted_positive_returns = 0\n",
    "    num_observations = 0\n",
    "    for i, (trainX, trainY) in tqdm.tqdm(enumerate(dataloader_train), total=len(dataset_train) // BATCH_SIZE):\n",
    "        trainX, trainY = Variable(trainX).cuda(), Variable(trainY).cuda()\n",
    "        outputs = lstm(trainX)\n",
    "        correct += torch.max(outputs.data, 1)[1].eq(torch.max(trainY.data, 1)[1]).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "        num_positive_returns += trainY[:, [1]].sum()\n",
    "        num_observations += len(trainY)\n",
    "\n",
    "    accuracies.append(correct / len(dataloader_train.dataset))\n",
    "    losses.append(loss.cpu().data[0])\n",
    "    num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "\n",
    "    clear_output(True)\n",
    "    print(f'epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    print(f'actual positive returns {num_positive_returns}/{num_observations}: {num_positive_returns/num_observations}')\n",
    "    print(f'predicted positive_returns {predicted_positive_returns}/{num_observations}: {predicted_positive_returns/num_observations}')\n",
    "    \n",
    "    correct = 0\n",
    "    num_positive_returns = 0\n",
    "    predicted_positive_returns = 0\n",
    "    num_observations = 0\n",
    "    for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "        testX, testY = Variable(testX).cuda(), Variable(testY).cuda()\n",
    "        outputs = lstm(testX)\n",
    "        predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "        correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "        predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "        num_positive_returns += testY[:, [1]].sum()\n",
    "\n",
    "    loss = loss_fn(outputs, trainY)\n",
    "    accuracy = correct / len(dataloader_test.dataset)\n",
    "    test_accuracies.append(accuracy)\n",
    "    num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "    test_predicted_positives.append(predicted_positive_returns/len(dataloader_test.dataset))\n",
    "    \n",
    "    print(f'loss: {loss.data[0]}, accuracy: {accuracy}')\n",
    "    print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "    print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')\n",
    "    \n",
    "    plotly.iplot(go.Figure(data=[go.Scatter(x=list(range(len(losses))), y=losses, name='loss'),\n",
    "                                 go.Scatter(x=list(range(len(accuracies))), y=accuracies, name='train_accuracy', yaxis='y2'),\n",
    "                                 go.Scatter(x=list(range(len(test_accuracies))), y=test_accuracies, name='test_accuracy', yaxis='y2'),\n",
    "                                 go.Scatter(x=list(range(len(test_predicted_positives))), y=test_predicted_positives, name='test_predicted_positives', yaxis='y2')],\n",
    "                           layout=go.Layout(yaxis={'title': 'loss'}, yaxis2={'title': 'accuracy', 'overlaying': 'y', 'side': 'right'})))\n",
    "    plotly.plot(go.Figure(data=[go.Scatter(x=list(range(len(losses))), y=losses, name='loss'),\n",
    "                                go.Scatter(x=list(range(len(accuracies))), y=accuracies, name='train_accuracy', yaxis='y2'),\n",
    "                                go.Scatter(x=list(range(len(test_accuracies))), y=test_accuracies, name='test_accuracy', yaxis='y2'),\n",
    "                                go.Scatter(x=list(range(len(test_predicted_positives))), y=test_predicted_positives, name='test_predicted_positives', yaxis='y2')],\n",
    "                          layout=go.Layout(yaxis={'title': 'loss'}, yaxis2={'title': 'accuracy', 'overlaying': 'y', 'side': 'right'})),\n",
    "               filename=f'models/training{epoch}.html')\n",
    "    data = pd.DataFrame(outputs.cpu().data.numpy())\n",
    "    plotly.plot(go.Figure(data=[go.Scatter(x=data.sample(n=1000).values[:, 0], y=data.sample(n=1000).values[:, 1], mode='markers')],\n",
    "                       layout=go.Layout(width=600, height=600)), filename=f'models/scatter{epoch}.html')\n",
    "    print(outputs)\n",
    "    torch.save(lstm.state_dict(), f'models/{epoch}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:05<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5318581461906433, accuracy: 0.7052266666666667\n",
      "actual positive returns 260951.0/525000: 0.49704952380952383\n",
      "predicted positive_returns 368879/525000: 0.7026266666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_positive_returns = 0\n",
    "predicted_positive_returns = 0\n",
    "num_observations = 0\n",
    "for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "    testX, testY = Variable(testX).cuda(), Variable(testY).cuda()\n",
    "    outputs = lstm(testX)\n",
    "    predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "    correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "    predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "    num_positive_returns += testY[:, [1]].sum()\n",
    "\n",
    "loss = loss_fn(outputs, testY)\n",
    "accuracy = correct / len(dataloader_test.dataset)\n",
    "num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "\n",
    "print(f'loss: {loss.data[0]}, accuracy: {accuracy}')\n",
    "print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_state_dict(torch.load('models/2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
