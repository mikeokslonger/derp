{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from plotly import offline as plotly\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "plotly.init_notebook_mode(True)\n",
    "np = pd.np\n",
    "\n",
    "### Hyper Parameters\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 1000\n",
    "NUM_EPOCHS = 10\n",
    "INPUT_SIZE = NUM_FEATURES = 1\n",
    "HIDDEN_SIZE = 200\n",
    "NUM_CLASSES = 2\n",
    "SEQ_LENGTH = 100\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "def read_returns(pair):\n",
    "    path = f'/media/mikeokslonger/data/returns.parquet/pair={pair}/part.0.parquet'\n",
    "    path = f's3://mikeokslonger-ticks/returns.parquet/pair={pair}/part.0.parquet'\n",
    "    df = pd.read_parquet(path, columns=['time', 'relative_returns', 'buy', 'quantity', 'price'])\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    one_hot = np.array([[1, 0],\n",
    "                       [0, 1]], dtype='float32')\n",
    "    df['buy'] = df['buy'].astype(float)\n",
    "    df['label'] = (df.shift(-1)['relative_returns'] > 0.).astype(int)\n",
    "    df['label_onehot'] = df['label'].apply(lambda i: one_hot[i])\n",
    "    df['time'] = (df['time'] - 20180101000000).astype(float)\n",
    "    return df[1:]\n",
    "\n",
    "pairs = ['ADX-USD', 'AIR-USD', 'AMM-USD', 'ATB-USD', 'ATM-USD', 'B2X-USD', 'BCC-USD', 'BCH-USD', 'BCN-USD', 'BMC-USD', 'BNT-USD', 'BQX-USD', 'BTCA-USD', 'BTC-USD', 'BTG-USD', 'BTM-USD', 'BTX-USD', 'CAT-USD', 'CDT-USD', 'CLD-USD', 'CL-USD', 'CND-USD', 'CTR-USD', 'CVC-USD', 'DASH-USD', 'DATA-USD', 'DCN-USD', 'DGB-USD', 'DIM-USD', 'DOGE-USD', 'EBTCOLD-USD', 'EDO-USD', 'EMGO-USD', 'ENJ-USD', 'EOS-USD', 'ETC-USD', 'ETH-USD', 'ETP-USD', 'EVX-USD', 'FUEL-USD', 'FUN-USD', 'ICOS-USD', 'ICX-USD', 'KMD-USD', 'LOC-USD', 'LSK-USD', 'LTC-USD', 'MAID-USD', 'MANA-USD', 'MCO-USD', 'NEO-USD', 'NGC-USD', 'NXT-USD', 'OAX-USD', 'OMG-USD', 'PLR-USD', 'PPC-USD', 'PRG-USD', 'QTUM-USD', 'SMART-USD', 'SMS-USD', 'SNC-USD', 'SNT-USD', 'STRAT-USD', 'STU-USD', 'STX-USD', 'SUB-USD', 'SUR-USD', 'SWFTC-USD', 'TNT-USD', 'TRX-USD', 'UGT-USD', 'UTT-USD', 'VEN-USD', 'VERI-USD', 'VIB-USD', 'WMGO-USD', 'WRC-USD', 'XDN-USD', 'XEM-USD', 'XMR-USD', 'XTZ-USD', 'XUC-USD', 'XVG-USD', 'ZEC-USD', 'ZRX-USD', 'ZSC-USD']\n",
    "\n",
    "#pairs = !ls /media/mikeokslonger/data/returns.parquet/ | grep pair\n",
    "#pairs = [p.split('=')[1] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/87 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/87 [00:00<00:22,  3.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "Returns\n",
      "features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/87 [00:13<09:52,  6.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/87 [00:14<06:45,  4.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "Returns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 4/87 [00:14<05:07,  3.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "Returns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 5/87 [00:15<04:12,  3.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "Returns\n",
      "features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 6/87 [00:17<03:50,  2.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns\n",
      "features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 7/87 [00:18<03:29,  2.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([create_features(read_returns(pair)) for pair in tqdm.tqdm(pairs)]) # Full dataset\n",
    "df = df[df.relative_returns.abs() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = !ls /media/mikeokslonger/data/returns.parquet/ | grep pair\n",
    "pairs = [p.split('=')[1] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticks(Dataset):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.x_data = data[:, 1:2].copy().astype('float32')\n",
    "        self.y_data = data[:, -1].copy()#.astype('int')\n",
    "        \n",
    "        indices = pd.DataFrame(data[:, -2] == 0,columns=['isnegative']).reset_index()\n",
    "        positive_indices = indices[~indices.isnegative]['index']\n",
    "        negative_indices = indices[indices.isnegative]['index']\n",
    "        negative_indices_resampled = negative_indices.sample(frac=len(positive_indices)/len(negative_indices))\n",
    "        self.new_indices = pd.np.concatenate([positive_indices, negative_indices_resampled])\n",
    "        self.new_indices.sort()\n",
    "        \n",
    "        self.len = len(self.new_indices) - SEQ_LENGTH - ((len(self.new_indices) - SEQ_LENGTH) % batch_size)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        new_index = self.new_indices[index]\n",
    "        x = self.x_data[new_index: new_index + SEQ_LENGTH]\n",
    "        return x, self.y_data[new_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "#        return 1000000\n",
    "        return self.len\n",
    "\n",
    "\n",
    "test_validation_split = int(len(df) * 0.8)\n",
    "dataset_train = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[:test_validation_split], BATCH_SIZE)\n",
    "dataset_test = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[test_validation_split:], BATCH_SIZE)\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Model\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### (LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # Hidden\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # Cell state\n",
    "        _, (h_out, _) = self.lstm(x, (h0, c0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        activated = self.sig(out)\n",
    "        return activated\n",
    "\n",
    "\n",
    "lstm = LSTM(NUM_CLASSES, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "lstm.load_state_dict(torch.load('/home/mikeokslonger/Downloads/180.pt', map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# TRAIN\n",
    "\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/10\n",
      "actual positive returns 233102.0/466000\n",
      "predicted positive_returns 210004/466000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "loss",
         "type": "scatter",
         "uid": "8596ed",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.6941065192222595,
          0.6930015683174133,
          0.6932742595672607,
          0.6930700540542603,
          0.6931912302970886,
          0.6930273771286011,
          0.6931394338607788
         ]
        },
        {
         "name": "accuracy",
         "type": "scatter",
         "uid": "089d0a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.4996695278969957,
          0.49972317596566523,
          0.5003090128755365,
          0.5010772532188841,
          0.4995965665236051,
          0.49955150214592275,
          0.4995236051502146
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "autosize": true,
        "xaxis": {
         "autorange": true,
         "range": [
          -0.3575581395348837,
          6.357558139534884
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.6929103830485668,
          0.6941977044911061
         ],
         "title": "loss",
         "type": "linear"
        },
        "yaxis2": {
         "autorange": true,
         "overlaying": "y",
         "range": [
          0.4993953914746448,
          0.5012054668944539
         ],
         "side": "right",
         "title": "accuracy",
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"08855fe8-f675-470b-b4ce-f241a8f5423b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"08855fe8-f675-470b-b4ce-f241a8f5423b\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.6941065192222595, 0.6930015683174133, 0.6932742595672607, 0.6930700540542603, 0.6931912302970886, 0.6930273771286011, 0.6931394338607788], \"name\": \"loss\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.4996695278969957, 0.49972317596566523, 0.5003090128755365, 0.5010772532188841, 0.4995965665236051, 0.49955150214592275, 0.4995236051502146], \"name\": \"accuracy\", \"yaxis\": \"y2\"}], {\"yaxis\": {\"title\": \"loss\"}, \"yaxis2\": {\"title\": \"accuracy\", \"overlaying\": \"y\", \"side\": \"right\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"08855fe8-f675-470b-b4ce-f241a8f5423b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"08855fe8-f675-470b-b4ce-f241a8f5423b\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.6941065192222595, 0.6930015683174133, 0.6932742595672607, 0.6930700540542603, 0.6931912302970886, 0.6930273771286011, 0.6931394338607788], \"name\": \"loss\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.4996695278969957, 0.49972317596566523, 0.5003090128755365, 0.5010772532188841, 0.4995965665236051, 0.49955150214592275, 0.4995236051502146], \"name\": \"accuracy\", \"yaxis\": \"y2\"}], {\"yaxis\": {\"title\": \"loss\"}, \"yaxis2\": {\"title\": \"accuracy\", \"overlaying\": \"y\", \"side\": \"right\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000,  0.5000],\n",
      "        [ 0.5000,  0.5000],\n",
      "        [ 0.5000,  0.5000],\n",
      "        ...,\n",
      "        [ 0.5000,  0.5000],\n",
      "        [ 0.5000,  0.5000],\n",
      "        [ 0.5000,  0.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/466 [00:52<2:14:27, 17.42s/it]Process Process-15:\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 102517) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2962\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2963\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2964\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2589b157fbca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 102517) exited unexpectedly with exit code 1."
     ]
    }
   ],
   "source": [
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in list(range(NUM_EPOCHS)):\n",
    "    correct = 0\n",
    "    \n",
    "    num_positive_returns = 0\n",
    "    predicted_positive_returns = 0\n",
    "    num_observations = 0\n",
    "    for i, (trainX, trainY) in tqdm.tqdm(enumerate(dataloader_train), total=len(dataset_train) // BATCH_SIZE):\n",
    "        outputs = lstm(trainX)\n",
    "        correct += torch.max(outputs.data, 1)[1].eq(torch.max(trainY.data, 1)[1]).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "        num_positive_returns += trainY[:, [1]].sum()\n",
    "        num_observations += len(trainY)\n",
    "\n",
    "    accuracies.append(correct.item() / len(dataloader_train.dataset))\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(f'epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    print(f'actual positive returns {num_positive_returns}/{num_observations}')\n",
    "    print(f'predicted positive_returns {predicted_positive_returns}/{num_observations}')\n",
    "    \n",
    "    plotly.iplot(go.Figure(data=[go.Scatter(x=list(range(len(losses))), y=losses, name='loss'),\n",
    "                                 go.Scatter(x=list(range(len(accuracies))), y=accuracies, name='accuracy', yaxis='y2')],\n",
    "                           layout=go.Layout(yaxis={'title': 'loss'}, yaxis2={'title': 'accuracy', 'overlaying': 'y', 'side': 'right'})))\n",
    "    print(outputs)\n",
    "    \n",
    "correct = 0\n",
    "for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "    outputs = lstm(testX)\n",
    "    predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "    correct += predicted_labels.eq(testY[:, [1]].view(-1).long()).sum()\n",
    "\n",
    "loss = loss_fn(outputs, trainY)\n",
    "accuracy = correct.item() / len(dataloader_test.dataset)\n",
    "print(f'loss: {loss}, accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "num_positive_returns = 0\n",
    "predicted_positive_returns = 0\n",
    "num_observations = 0\n",
    "for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "    testX, testY = Variable(testX), Variable(testY)\n",
    "    outputs = lstm(testX)\n",
    "    predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "    correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "    predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "    num_positive_returns += testY[:, [1]].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0134743452072144, accuracy: 0.5325142857142857\n",
      "actual positive returns 17191.0/35000: 0.4911714196205139\n",
      "predicted positive_returns 2291/35000: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning:\n",
      "\n",
      "invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n",
      "/home/mikeokslonger/miniconda2/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning:\n",
      "\n",
      "invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(outputs, testY)\n",
    "accuracy = correct.item() / len(dataloader_test.dataset)\n",
    "num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "\n",
    "print(f'loss: {loss.data[0]}, accuracy: {accuracy}')\n",
    "print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
